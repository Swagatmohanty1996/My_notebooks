{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"winequality-white.csv\", sep = ';')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"winequality-white.csv\", sep = ';')\n",
    "y = df.pop('quality')\n",
    "for i in df.columns:\n",
    "    df[i] = df[i].fillna(np.mean(df[i]))\n",
    "train, test, y_train, y_test = train_test_split(df, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.linear_model.logistic.LogisticRegression"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score baseline: 0.5153061224489796\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train, y_train)\n",
    "y_pred = lr.predict(test)\n",
    "print('Accuracy score baseline:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=20, n_jobs=1, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 20, oob_score=True)\n",
    "rf.fit(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345074017355794"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fit_predict(train, test, y_train, y_test,  max_depth = None , \n",
    "                n_estimators = 10, max_features = 'auto', min_samples_split = 2,scaler = None):\n",
    "    if scaler:\n",
    "        train = scaler.fit_transform(train)\n",
    "        test = scaler.transform(test)        \n",
    "    RF = RandomForestClassifier(n_estimators = n_estimators, max_depth=max_depth, \n",
    "                                random_state = 42, max_features = max_features,\n",
    "                               min_samples_split = min_samples_split,oob_score=True)\n",
    "    RF.fit(train, y_train)\n",
    "    y_pred = RF.predict(test)\n",
    "    print(accuracy_score(y_test, y_pred))\n",
    "    print(RF.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy score: 0.6448979591836734\n",
      "0.5890760592138846\n",
      "baseline accuracy score with scaler: 0.6418367346938776\n",
      "0.5872894333843798\n"
     ]
    }
   ],
   "source": [
    "print('baseline accuracy score', end = ': ')\n",
    "fit_predict(train,test,y_train,y_test)\n",
    "print('baseline accuracy score with scaler', end = ': ')\n",
    "fit_predict(train,test,y_train,y_test,scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using n_estimators = 20: 0.6612244897959184\n",
      "Accuracy score using n_estimators = 40: 0.6775510204081633\n",
      "Accuracy score using n_estimators = 60: 0.6846938775510204\n",
      "Accuracy score using n_estimators = 80: 0.6877551020408164\n",
      "Accuracy score using n_estimators = 100: 0.689795918367347\n",
      "Accuracy score using n_estimators = 120: 0.6979591836734694\n",
      "Accuracy score using n_estimators = 140: 0.6908163265306122\n",
      "Accuracy score using n_estimators = 160: 0.6979591836734694\n",
      "Accuracy score using n_estimators = 180: 0.6948979591836735\n"
     ]
    }
   ],
   "source": [
    "for n_estimators in range(20,200,20):\n",
    "    print('Accuracy score using n_estimators =', n_estimators, end = ': ')\n",
    "    fit_predict(train,test,y_train,y_test,n_estimators = n_estimators)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using max_depth = 1: 0.44081632653061226\n",
      "Accuracy score using max_depth = 2: 0.4897959183673469\n",
      "Accuracy score using max_depth = 3: 0.49387755102040815\n",
      "Accuracy score using max_depth = 4: 0.5051020408163265\n",
      "Accuracy score using max_depth = 5: 0.5244897959183673\n",
      "Accuracy score using max_depth = 6: 0.536734693877551\n",
      "Accuracy score using max_depth = 7: 0.563265306122449\n",
      "Accuracy score using max_depth = 8: 0.5826530612244898\n",
      "Accuracy score using max_depth = 9: 0.5948979591836735\n",
      "Accuracy score using max_depth = 10: 0.6091836734693877\n",
      "Accuracy score using max_depth = 11: 0.6469387755102041\n",
      "Accuracy score using max_depth = 12: 0.6744897959183673\n",
      "Accuracy score using max_depth = 13: 0.6816326530612244\n",
      "Accuracy score using max_depth = 14: 0.6979591836734694\n",
      "Accuracy score using max_depth = 15: 0.7\n",
      "Accuracy score using max_depth = 16: 0.6938775510204082\n",
      "Accuracy score using max_depth = 17: 0.6989795918367347\n",
      "Accuracy score using max_depth = 18: 0.6989795918367347\n",
      "Accuracy score using max_depth = 19: 0.7010204081632653\n"
     ]
    }
   ],
   "source": [
    "for max_depth in range(1,20):\n",
    "    print('Accuracy score using max_depth =', max_depth, end = ': ')\n",
    "    fit_predict(train,test,y_train,y_test,n_estimators = 160,max_depth = max_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using max_features = 0.1: 0.6979591836734694\n",
      "Accuracy score using max_features = 0.2: 0.7030612244897959\n",
      "Accuracy score using max_features = 0.30000000000000004: 0.6989795918367347\n",
      "Accuracy score using max_features = 0.4: 0.6969387755102041\n",
      "Accuracy score using max_features = 0.5: 0.6989795918367347\n",
      "Accuracy score using max_features = 0.6: 0.6938775510204082\n",
      "Accuracy score using max_features = 0.7000000000000001: 0.6989795918367347\n",
      "Accuracy score using max_features = 0.8: 0.7010204081632653\n",
      "Accuracy score using max_features = 0.9: 0.6979591836734694\n",
      "Accuracy score using max_features = 1.0: 0.7051020408163265\n"
     ]
    }
   ],
   "source": [
    "for max_features in np.linspace(0.1,1,10):\n",
    "    print('Accuracy score using max_features =', max_features, end = ': ')\n",
    "    fit_predict(train,test,y_train,y_test,n_estimators = 160,max_features = max_features,max_depth = 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using min_samples_split = 2: 0.7030612244897959\n",
      "Accuracy score using min_samples_split = 3: 0.7193877551020408\n",
      "Accuracy score using min_samples_split = 4: 0.7030612244897959\n",
      "Accuracy score using min_samples_split = 5: 0.6979591836734694\n",
      "Accuracy score using min_samples_split = 6: 0.6928571428571428\n",
      "Accuracy score using min_samples_split = 7: 0.6816326530612244\n",
      "Accuracy score using min_samples_split = 8: 0.6775510204081633\n",
      "Accuracy score using min_samples_split = 9: 0.6724489795918367\n"
     ]
    }
   ],
   "source": [
    "for min_samples_split in range(2,10):\n",
    "    print('Accuracy score using min_samples_split =', min_samples_split, end = ': ')\n",
    "    fit_predict(train,test,y_train,y_test,n_estimators = 160,max_features = 0.2,min_samples_split=min_samples_split\n",
    "               ,max_depth = 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned accuracy score: 0.7193877551020408\n",
      "tuned accuracy score with scaler: 0.7193877551020408\n"
     ]
    }
   ],
   "source": [
    "print('tuned accuracy score', end = ': ')\n",
    "fit_predict(train,test,y_train,y_test,n_estimators = 160,max_features = 0.2,min_samples_split=3,max_depth = 18)\n",
    "print('tuned accuracy score with scaler', end = ': ')\n",
    "\n",
    "fit_predict(train,test,y_train,y_test,n_estimators = 160,max_features = 0.2,min_samples_split=3,\n",
    "            max_depth = 18,scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall improvement is 39.88 %\n"
     ]
    }
   ],
   "source": [
    "original_score = 0.514285714286\n",
    "best_score = 0.7193877551020408\n",
    "improvement = np.abs(np.round(100*(original_score - best_score)/original_score,2))\n",
    "print('overall improvement is {} %'.format(improvement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall improvement compare to non tuned model is 11.9 %\n"
     ]
    }
   ],
   "source": [
    "original_score = 0.6428571428571429\n",
    "best_score = 0.7193877551020408\n",
    "improvement = np.abs(np.round(100*(original_score - best_score)/original_score,2))\n",
    "print('overall improvement compare to non tuned model is {} %'.format(improvement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
